{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80e8ffac-8f9f-4c30-a39f-48a178853654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba1fc10-ba90-45ba-9183-f68f4c5edae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = load_dataset(\"squad\", split=\"train[:40000]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d070d7b7-d23f-4cbc-8781-c2ab7f358194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dante\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "938fb4b0-e334-4a0d-808e-4087cfcd715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb0af8a-0ac9-4cc4-ab4a-66c404807f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = squad.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a1e6512-e0d3-41cd-9bac-bb0dfd162078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 36000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b9ad606-c686-4dec-af83-eb8f981bcf6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56df72ab5ca0a614008f9a7b',\n",
       " 'title': 'Oklahoma_City',\n",
       " 'context': 'The Oklahoma City Zoo and Botanical Garden is home to numerous natural habitats, WPA era architecture and landscaping, and hosts major touring concerts during the summer at its amphitheater. Oklahoma City also has two amusement parks, Frontier City theme park and White Water Bay water park. Frontier City is an \\'Old West\\'-themed amusement park. The park also features a recreation of a western gunfight at the \\'OK Corral\\' and many shops that line the \"Western\" town\\'s main street. Frontier City also hosts a national concert circuit at its amphitheater during the summer. Oklahoma City also has a combination racetrack and casino open year-round, Remington Park, which hosts both Quarter horse (March – June) and Thoroughbred (August – December) seasons.',\n",
       " 'question': 'Which amusement park is western themed? ',\n",
       " 'answers': {'text': ['Frontier City'], 'answer_start': [235]}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "960dcf0b-dc9d-4bc4-8444-cb5ddd05da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_samples(example):\n",
    "    \"\"\"\n",
    "    Returns bool for valid samples. Each sample must:\n",
    "    1. Have an answer\n",
    "    2. Have a question\n",
    "    3. The answer must be in the context    \n",
    "    \"\"\"\n",
    "    # Check if there are no answers\n",
    "    if example[\"answers\"][\"text\"] == []: return False\n",
    "    answer = example[\"answers\"][\"text\"][0]\n",
    "\n",
    "    valid = example[\"question\"] != \"\" and answer in example[\"context\"] \n",
    "    return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1bab0e4f-0319-4010-a605-99d5347185d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21500e8a56cf4bc8a69c9acd3f0f3160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/36000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef435a0552c454e8eb0a79f4069a030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 36000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad.filter(filter_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3cb6909f-8bb9-466e-b175-f87309a11646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer_sentence(context, answer):\n",
    "    \"\"\"\n",
    "    Extracts the sentence containing the answer from the context.\n",
    "    \n",
    "    Args:\n",
    "    - example: A dictionary representing a SQuaD example.\n",
    "    \n",
    "    Returns:\n",
    "    - Modified example with the 'context' field replaced by the sentence containing the answer.\n",
    "    \"\"\"\n",
    "    # Split the context into sentences\n",
    "    sentences = sent_tokenize(context)\n",
    "    # Return the sentences that contain the answer's name\n",
    "    return \" \".join(filter(lambda s: answer in s, sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8cc12e48-1d33-41d6-a18b-ca3b07eb526c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Oklahoma City Zoo and Botanical Garden is home to numerous natural habitats, WPA era architecture and landscaping, and hosts major touring concerts during the summer at its amphitheater. Oklahoma City also has two amusement parks, Frontier City theme park and White Water Bay water park. Frontier City is an 'Old West'-themed amusement park. The park also features a recreation of a western gunfight at the 'OK Corral' and many shops that line the \"Western\" town's main street. Frontier City also hosts a national concert circuit at its amphitheater during the summer. Oklahoma City also has a combination racetrack and casino open year-round, Remington Park, which hosts both Quarter horse (March – June) and Thoroughbred (August – December) seasons.\n",
      "Which amusement park is western themed? \n",
      "Frontier City\n",
      "Oklahoma City also has two amusement parks, Frontier City theme park and White Water Bay water park. Frontier City is an 'Old West'-themed amusement park. Frontier City also hosts a national concert circuit at its amphitheater during the summer.\n"
     ]
    }
   ],
   "source": [
    "example = squad[\"train\"][0]\n",
    "\n",
    "print(example[\"context\"])\n",
    "print(example[\"question\"])\n",
    "print(example[\"answers\"][\"text\"][0])\n",
    "\n",
    "print(extract_answer_sentence(example[\"context\"], example[\"answers\"][\"text\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ea7ef601-e9cd-4a9e-9062-df8167323ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This feast is called in older prayer books the Purification of the Blessed Virgin Mary on February 2.',\n",
       " 'Such institutional support may include government recognition or designation; presentation as being the \"correct\" form of a language in schools; published grammars, dictionaries, and textbooks that set forth a correct spoken and written form; and an extensive formal literature that employs that dialect (prose, poetry, non-fiction, etc.).',\n",
       " 'Quoted at constant 2002 prices, GDP fell from £12 million in 1999-2000 to £11 million in 2005-06.',\n",
       " 'Iran was Sunni at the time.']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = list(map(\n",
    "    lambda c, a: extract_answer_sentence(c, a[\"text\"][0]),\n",
    "    squad[\"train\"][10:14][\"context\"],\n",
    "    squad[\"train\"][10:14][\"answers\"]\n",
    "))\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1db2a83c-1e02-4839-b574-30108c0b7c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['On what date is the Presentation of Christ in the Temple celebrated by Anglicans? February 2',\n",
       " 'Recognition from what body may help a dialect to become standardized? government',\n",
       " 'What was the GDP of the island in 1999-2000? £12 million',\n",
       " 'In the later Abbasid era, what branch of Islam did Iran adhere to? Sunni']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = list(map(\n",
    "    lambda q, a: f\"{q} {a[\"text\"][0]}\",\n",
    "    squad[\"train\"][10:14][\"question\"],\n",
    "    squad[\"train\"][10:14][\"answers\"]\n",
    "))\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8424ed09-52ce-4e99-b9e5-8bc48d71cb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"google-t5/t5-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7b9be4c2-2c53-48aa-b361-c4396ed2c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7e7ef9c3-8e3a-46b1-83bd-52629db7e436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Add the prompt to every context provided\n",
    "    inputs = list(map(\n",
    "        lambda c, a: extract_answer_sentence(c, a[\"text\"][0]),\n",
    "        examples[\"context\"],\n",
    "        examples[\"answers\"]\n",
    "    ))\n",
    "    \n",
    "    [\"ask: \" + context for context in examples[\"context\"]]\n",
    "    # Model every target as \"question? answer\"\n",
    "    targets = list(map(\n",
    "        lambda q, a: f\"{q} {a[\"text\"][0]}\",\n",
    "        examples[\"question\"],\n",
    "        examples[\"answers\"]\n",
    "    ))\n",
    "\n",
    "    model_inputs = tokenizer(inputs, max_length=512, padding=\"max_length\", truncation=True)\n",
    "    labels = tokenizer(text_target=targets, max_length=128, padding=\"max_length\", truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "979b7be4-2f9d-4a54-99d3-7b388faa37be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test what mapping over the samples would look like\n",
    "outputs = list(map(\n",
    "    lambda q, a: f\"Q: {q} A: {a[\"text\"][0]}\",\n",
    "    squad[\"train\"][:5][\"question\"],\n",
    "    squad[\"train\"][:5][\"answers\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3aa4b0b9-3e0e-4704-a095-5cf760f57b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Q: Where is Volkswagen Group's AutoEuropa assembly plant located? A: Palmela\",\n",
       " 'Q: For what movie did Beyonce receive  her first Golden Globe nomination? A: Dreamgirls',\n",
       " \"Q: Who provided information about the game's controls in December of 2005? A: NGC Magazine\",\n",
       " 'Q: Instead of being a single person, what does Whitehead view a person as? A: continuum of overlapping events',\n",
       " 'Q: What was the percentage increase in the Broadway ticket revenue from 2012-3 to 2013-4? A: 11.4%']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f1f040ba-b71b-4f32-98f9-d9be5bffcb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34997ae8b7184d9baaa37b496dabc57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_squad = squad.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8a827022-8d4f-46ab-94ca-2b08382c1a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 8000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "59e2eeb1-dd35-44b1-80f5-2526fa7fac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "59a2ab09-9103-4fca-a0ab-d7cc2643b515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f1c1c093-3f61-45f6-8ea6-15c38c274de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5476b4af-b411-442c-977c-fa5428f2b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "45b55987-450d-43c2-9707-5390c87b8df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=4,\n",
    "    logging_steps=10,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_squad[\"train\"],\n",
    "    eval_dataset=tokenized_squad[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "20a84d16-9e04-4a38-96f8-0af6f21f69db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 42:36, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.378300</td>\n",
       "      <td>0.309609</td>\n",
       "      <td>0.363900</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>0.324900</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>18.465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.357300</td>\n",
       "      <td>0.291394</td>\n",
       "      <td>0.371900</td>\n",
       "      <td>0.113000</td>\n",
       "      <td>0.330600</td>\n",
       "      <td>0.330700</td>\n",
       "      <td>18.499000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.330500</td>\n",
       "      <td>0.284827</td>\n",
       "      <td>0.374300</td>\n",
       "      <td>0.114100</td>\n",
       "      <td>0.333800</td>\n",
       "      <td>0.333600</td>\n",
       "      <td>18.484000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.327800</td>\n",
       "      <td>0.283001</td>\n",
       "      <td>0.376900</td>\n",
       "      <td>0.115800</td>\n",
       "      <td>0.336100</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>18.495500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MyProjects\\DawsonAI\\.env\\Lib\\site-packages\\transformers\\generation\\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "D:\\MyProjects\\DawsonAI\\.env\\Lib\\site-packages\\transformers\\generation\\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "D:\\MyProjects\\DawsonAI\\.env\\Lib\\site-packages\\transformers\\generation\\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2000, training_loss=0.6134686719179153, metrics={'train_runtime': 2557.6803, 'train_samples_per_second': 12.511, 'train_steps_per_second': 0.782, 'total_flos': 4330937647104000.0, 'train_loss': 0.6134686719179153, 'epoch': 4.0})"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c177f822-127d-4b93-bd63-3c9506f97708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "mcq_model = AutoModelForSeq2SeqLM.from_pretrained(\"results/checkpoint-2000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b8ad64dc-8721-4231-8fc9-85f53193a859",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"context: Chemical engineering involves the production and manufacturing of products through chemical processes. This includes designing equipment, systems, and processes for refining raw materials and for mixing, compounding, and processing chemicals.\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "36fe3acc-27dd-4f46-bfe0-b1d8f7ec90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = mcq_model.generate(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "71a51cff-4e12-4e19-bd6b-0e69643c7208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> Q: What is the process of chemical engineering? A: manufacturing</s>'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cd6f00-b2ed-4496-b197-5b9a0bfdb458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
