{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a030ea-18c3-4339-bf9e-28429db73b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "779512e7-6438-46b0-94cc-a6ec71482e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use the QASC dataset from AllenAI Institute\n",
    "qasc = load_dataset(\"qasc\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34c2b516-4c7f-4f6e-9af0-6380137339f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the answers in the QASC dataset come in this format\n",
    "keys = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6080bd0a-84b8-40b0-9754-5c0b93a1ed34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'question', 'choices', 'answerKey', 'fact1', 'fact2', 'combinedfact', 'formatted_question'],\n",
       "    num_rows: 8134\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qasc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e738f5a-7bcc-44d4-af04-6a969eec301a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '3TMSXRD2X6Z77PSX9W0GF5UB1E9W1E',\n",
       " 'question': 'What animal can hunt at night?',\n",
       " 'choices': {'text': ['food',\n",
       "   'fish',\n",
       "   'bird',\n",
       "   'owl',\n",
       "   'deer',\n",
       "   'cows',\n",
       "   'rhinos',\n",
       "   'frog'],\n",
       "  'label': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
       " 'answerKey': '',\n",
       " 'fact1': '',\n",
       " 'fact2': '',\n",
       " 'combinedfact': '',\n",
       " 'formatted_question': 'What animal can hunt at night? (A) food (B) fish (C) bird (D) owl (E) deer (F) cows (G) rhinos (H) frog'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qasc[\"test\"][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74f72fe3-8d51-4451-9f44-2678356b5ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1dfc8e6188d4016ac9e78228bf0610f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/8134 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6250b1506e474fc0b3bb4ffd368d7cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/920 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514386d7493c43df80b8904bd2b71584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/926 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'question', 'choices', 'answerKey', 'fact1', 'fact2', 'combinedfact', 'formatted_question'],\n",
       "        num_rows: 8134\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'question', 'choices', 'answerKey', 'fact1', 'fact2', 'combinedfact', 'formatted_question'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'question', 'choices', 'answerKey', 'fact1', 'fact2', 'combinedfact', 'formatted_question'],\n",
       "        num_rows: 926\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We must remove any questions for which the answerKey is not present\n",
    "qasc.filter(lambda example: example[\"answerKey\"] in keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5217c388-d5cc-4da7-be53-481a2f312407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '3E7TUJ2EGCLQNOV1WEAJ2NN9ROPD9K',\n",
       " 'question': 'What type of water formation is formed by clouds?',\n",
       " 'choices': {'text': ['pearls',\n",
       "   'streams',\n",
       "   'shells',\n",
       "   'diamonds',\n",
       "   'rain',\n",
       "   'beads',\n",
       "   'cooled',\n",
       "   'liquid'],\n",
       "  'label': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
       " 'answerKey': 'F',\n",
       " 'fact1': 'beads of water are formed by water vapor condensing',\n",
       " 'fact2': 'Clouds are made of water vapor.',\n",
       " 'combinedfact': 'Beads of water can be formed by clouds.',\n",
       " 'formatted_question': 'What type of water formation is formed by clouds? (A) pearls (B) streams (C) shells (D) diamonds (E) rain (F) beads (G) cooled (H) liquid'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to get an idea of what each sample looks like!\n",
    "qasc[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "768ba305-5aa5-4498-bd61-f7864340d288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our model of choice, let's use the T5 small\n",
    "checkpoint = \"google-t5/t5-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0d1a4e9-f1d8-46d0-96d0-0ca3d0303c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MyProjects\\DawsonAI\\.env\\Lib\\site-packages\\transformers\\utils\\hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5ef9b27-ef99-4f2c-bdee-dff406049e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_targets(examples):\n",
    "    \"\"\"\n",
    "    Each statement should correspond to a \"Question? Answer\" output\n",
    "    \"\"\"\n",
    "    # Answers are always listed alphabetically in series of 8\n",
    "    keys = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]\n",
    "    \n",
    "    # We get each question to each sentence\n",
    "    questions = examples[\"question\"]\n",
    "    # We extract the answers to each question\n",
    "    answers = list(map(\n",
    "        lambda choices, answerKey: choices[keys.index(answerKey)],\n",
    "        [x[\"text\"] for x in examples[\"choices\"]],\n",
    "        examples[\"answerKey\"]\n",
    "    ))\n",
    "\n",
    "    # The form is \"question? answer\"\n",
    "    targets = list(map(\n",
    "        lambda q, a: f\"{q} {a}\",\n",
    "        questions,\n",
    "        answers\n",
    "    ))\n",
    "    \n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f10d0fca-3a4a-469c-907c-ca9400d522b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beads of water can be formed by clouds.', 'Vapor turning into a liquid leaves behind beads of water', 'Steam forms beads of water.']\n",
      "['What type of water formation is formed by clouds? beads', 'Where do beads of water come from? Vapor turning into a liquid', 'What forms beads of water?  Steam.', 'what kind of beads are formed from vapor condensing? h2o']\n"
     ]
    }
   ],
   "source": [
    "print(qasc[\"train\"][:3][\"combinedfact\"])\n",
    "print(generate_targets(qasc[\"train\"][:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1639cc28-c741-432a-ae68-fe07416beb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    \"\"\" \n",
    "    The objective of our model is to transform a sentence into a question.\n",
    "    To do so, the input to the model will be the sentence itself.\n",
    "    The output of the model, then, must be the question with the answer.\n",
    "    The model inputs will be the combined facts.\n",
    "    The model targets are the questions followed by the answer.\n",
    "    \"\"\"\n",
    "    prompt = \"ask: \" # Each input will be formatted as \"ask: sentence...\"\n",
    "    inputs = [prompt + sen for sen in examples[\"combinedfact\"]]\n",
    "    # We get each question to each sentence\n",
    "    questions = examples[\"question\"]\n",
    "    # We generate a target for each statement, a question and its answer\n",
    "    targets = generate_targets(examples)\n",
    "\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "    labels = tokenizer(text_target=targets, max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd57d3a5-3ee7-48ee-a99f-88e9bca90eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e10c0fe71d84e68a6b9c1e9920464b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8134 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9496ba217f4d5b8b4eae9fa7f46357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/920 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "'' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenized_qasc \u001b[38;5;241m=\u001b[39m \u001b[43mqasc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\MyProjects\\DawsonAI\\.env\\Lib\\site-packages\\datasets\\dataset_dict.py:869\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[0;32m    867\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m    868\u001b[0m     {\n\u001b[1;32m--> 869\u001b[0m         k: \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    889\u001b[0m     }\n\u001b[0;32m    890\u001b[0m )\n",
      "File \u001b[1;32mD:\\MyProjects\\DawsonAI\\.env\\Lib\\site-packages\\datasets\\arrow_dataset.py:593\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    591\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    592\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 593\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    594\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32mD:\\MyProjects\\DawsonAI\\.env\\Lib\\site-packages\\datasets\\arrow_dataset.py:558\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    551\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    556\u001b[0m }\n\u001b[0;32m    557\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 558\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mD:\\MyProjects\\DawsonAI\\.env\\Lib\\site-packages\\datasets\\arrow_dataset.py:3105\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3100\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3101\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3102\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3103\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3104\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3105\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3106\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3107\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[1;32mD:\\MyProjects\\DawsonAI\\.env\\Lib\\site-packages\\datasets\\arrow_dataset.py:3482\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3478\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   3479\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[0;32m   3480\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[0;32m   3481\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3482\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3486\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3487\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3488\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[0;32m   3489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[0;32m   3490\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3491\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\MyProjects\\DawsonAI\\.env\\Lib\\site-packages\\datasets\\arrow_dataset.py:3361\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[0;32m   3360\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[1;32m-> 3361\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3363\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3364\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[0;32m   3365\u001b[0m     }\n",
      "Cell \u001b[1;32mIn[21], line 14\u001b[0m, in \u001b[0;36mpreprocess_function\u001b[1;34m(examples)\u001b[0m\n\u001b[0;32m     12\u001b[0m questions \u001b[38;5;241m=\u001b[39m examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# We generate a target for each statement, a question and its answer\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m targets \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m tokenizer(inputs, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m labels \u001b[38;5;241m=\u001b[39m tokenizer(text_target\u001b[38;5;241m=\u001b[39mtargets, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[17], line 11\u001b[0m, in \u001b[0;36mgenerate_targets\u001b[1;34m(examples)\u001b[0m\n\u001b[0;32m      9\u001b[0m questions \u001b[38;5;241m=\u001b[39m examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# We extract the answers to each question\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m answers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchoices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswerKey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswerKey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manswerKey\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# The form is \"question? answer\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m q, a: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m     questions,\n\u001b[0;32m     21\u001b[0m     answers\n\u001b[0;32m     22\u001b[0m ))\n",
      "Cell \u001b[1;32mIn[17], line 12\u001b[0m, in \u001b[0;36mgenerate_targets.<locals>.<lambda>\u001b[1;34m(choices, answerKey)\u001b[0m\n\u001b[0;32m      9\u001b[0m questions \u001b[38;5;241m=\u001b[39m examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# We extract the answers to each question\u001b[39;00m\n\u001b[0;32m     11\u001b[0m answers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m choices, answerKey: choices[\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswerKey\u001b[49m\u001b[43m)\u001b[49m],\n\u001b[0;32m     13\u001b[0m     [x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m]],\n\u001b[0;32m     14\u001b[0m     examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswerKey\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     15\u001b[0m ))\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# The form is \"question? answer\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m q, a: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m     questions,\n\u001b[0;32m     21\u001b[0m     answers\n\u001b[0;32m     22\u001b[0m ))\n",
      "\u001b[1;31mValueError\u001b[0m: '' is not in list"
     ]
    }
   ],
   "source": [
    "tokenized_qasc = qasc.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40471ae5-172a-4446-80b3-52600ba985d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': ['3U0SRXB7CD45D0I0FPO8PDZXRHSRNK',\n",
       "  '351SEKWQS0G5U8EVLNEO79TTV8MMDS',\n",
       "  '39LNWE0K4UV5FRZQM36LPGQ02Y3IUO',\n",
       "  '3H8DHMCCW9AA4KES0B18SW1P5OLKDK'],\n",
       " 'question': ['Harming a certain kind of animal will cause the population of that animal to do what?',\n",
       "  'Meiosis is the type of cell division that produces:',\n",
       "  'Blowing on a fire increases what near a fire?',\n",
       "  'What reduces heat necessary for maximum predatory activity?'],\n",
       " 'choices': [{'text': ['decrease',\n",
       "    'eat more',\n",
       "    'increase',\n",
       "    'break off',\n",
       "    'threatened',\n",
       "    'reproduce',\n",
       "    'reduce',\n",
       "    'kill them'],\n",
       "   'label': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
       "  {'text': ['animals',\n",
       "    'Plant reproduction',\n",
       "    'Most plants',\n",
       "    'peachleaf willow',\n",
       "    'Plants growth',\n",
       "    'haploid cells',\n",
       "    'spread flower seeds',\n",
       "    'rapid expansion'],\n",
       "   'label': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
       "  {'text': ['the amount of oxygen',\n",
       "    'the sounds',\n",
       "    'kinetic energy',\n",
       "    'chlorofluorocarbons',\n",
       "    'the firewood',\n",
       "    'converting electricity to heat',\n",
       "    'heat energy',\n",
       "    'the electricity'],\n",
       "   'label': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']},\n",
       "  {'text': ['Evaporation',\n",
       "    'energy usage',\n",
       "    'warming',\n",
       "    'sweating',\n",
       "    'fur and fat',\n",
       "    'eating',\n",
       "    'tail fins',\n",
       "    'drinking'],\n",
       "   'label': ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']}],\n",
       " 'answerKey': ['A', 'F', 'A', 'D'],\n",
       " 'fact1': [\"harming an animal species causes that animal 's population to decrease\",\n",
       "  'Meiosis is the type of cell division that produces gametes.',\n",
       "  'fanning a fire increases the oxygen near the fire',\n",
       "  'Sweating reduces body heat.'],\n",
       " 'fact2': ['Species are the different kinds of organisms.',\n",
       "  'Gametes are haploid egg or sperm that fuse to form a zygote.',\n",
       "  'Fans blow directly above the oche.',\n",
       "  'High body heat is necessary for maximum predatory activity.'],\n",
       " 'combinedfact': [\"Harming a certain kind of organism causes that animal's population to decrease.\",\n",
       "  'Meiosis is the type of cell division that produces haploid cells.',\n",
       "  'Blowing on a fire increases the oxygen near the fire.',\n",
       "  'Sweating reduces  heat necessary for maximum predatory activity'],\n",
       " 'formatted_question': ['Harming a certain kind of animal will cause the population of that animal to do what? (A) decrease (B) eat more (C) increase (D) break off (E) threatened (F) reproduce (G) reduce (H) kill them',\n",
       "  'Meiosis is the type of cell division that produces: (A) animals (B) Plant reproduction (C) Most plants (D) peachleaf willow (E) Plants growth (F) haploid cells (G) spread flower seeds (H) rapid expansion',\n",
       "  'Blowing on a fire increases what near a fire? (A) the amount of oxygen (B) the sounds (C) kinetic energy (D) chlorofluorocarbons (E) the firewood (F) converting electricity to heat (G) heat energy (H) the electricity',\n",
       "  'What reduces heat necessary for maximum predatory activity? (A) Evaporation (B) energy usage (C) warming (D) sweating (E) fur and fat (F) eating (G) tail fins (H) drinking'],\n",
       " 'input_ids': [[987,\n",
       "   10,\n",
       "   3504,\n",
       "   51,\n",
       "   53,\n",
       "   3,\n",
       "   9,\n",
       "   824,\n",
       "   773,\n",
       "   13,\n",
       "   9329,\n",
       "   4110,\n",
       "   24,\n",
       "   2586,\n",
       "   31,\n",
       "   7,\n",
       "   2074,\n",
       "   12,\n",
       "   6313,\n",
       "   5,\n",
       "   1],\n",
       "  [987,\n",
       "   10,\n",
       "   1212,\n",
       "   23,\n",
       "   32,\n",
       "   7,\n",
       "   159,\n",
       "   19,\n",
       "   8,\n",
       "   686,\n",
       "   13,\n",
       "   2358,\n",
       "   4889,\n",
       "   24,\n",
       "   9560,\n",
       "   3,\n",
       "   9516,\n",
       "   20253,\n",
       "   2640,\n",
       "   5,\n",
       "   1],\n",
       "  [987, 10, 12861, 3108, 30, 3, 9, 1472, 5386, 8, 11035, 1084, 8, 1472, 5, 1],\n",
       "  [987,\n",
       "   10,\n",
       "   7320,\n",
       "   15,\n",
       "   1014,\n",
       "   1428,\n",
       "   7,\n",
       "   1678,\n",
       "   1316,\n",
       "   21,\n",
       "   2411,\n",
       "   23007,\n",
       "   63,\n",
       "   1756,\n",
       "   1]],\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " 'labels': [[3504,\n",
       "   51,\n",
       "   53,\n",
       "   3,\n",
       "   9,\n",
       "   824,\n",
       "   773,\n",
       "   13,\n",
       "   2586,\n",
       "   56,\n",
       "   1137,\n",
       "   8,\n",
       "   2074,\n",
       "   13,\n",
       "   24,\n",
       "   2586,\n",
       "   12,\n",
       "   103,\n",
       "   125,\n",
       "   58,\n",
       "   6313,\n",
       "   1],\n",
       "  [1212,\n",
       "   23,\n",
       "   32,\n",
       "   7,\n",
       "   159,\n",
       "   19,\n",
       "   8,\n",
       "   686,\n",
       "   13,\n",
       "   2358,\n",
       "   4889,\n",
       "   24,\n",
       "   9560,\n",
       "   10,\n",
       "   3,\n",
       "   9516,\n",
       "   20253,\n",
       "   2640,\n",
       "   1],\n",
       "  [12861,\n",
       "   3108,\n",
       "   30,\n",
       "   3,\n",
       "   9,\n",
       "   1472,\n",
       "   5386,\n",
       "   125,\n",
       "   1084,\n",
       "   3,\n",
       "   9,\n",
       "   1472,\n",
       "   58,\n",
       "   8,\n",
       "   866,\n",
       "   13,\n",
       "   11035,\n",
       "   1],\n",
       "  [363, 1428, 7, 1678, 1316, 21, 2411, 23007, 63, 1756, 58, 10242, 53, 1]]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_qasc[\"train\"][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f5c561b-4f48-407c-9b3c-9ccd0c74adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf5699f6-fb91-4285-80d5-1b92dbca13a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a489362-36fb-4445-9c28-0340a41456a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6402c2cb-2d13-4be2-8fc5-d8cb62f62735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41fbfb28-1a83-4794-8db4-d6d3a5def06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results_qasc\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=4,\n",
    "    logging_steps=10,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_qasc[\"train\"],\n",
    "    eval_dataset=tokenized_qasc[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11a62fb9-71da-41b8-b6d9-b75f6ad93dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1832' max='1832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1832/1832 14:28, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.451700</td>\n",
       "      <td>1.238196</td>\n",
       "      <td>0.831100</td>\n",
       "      <td>0.549200</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>13.702700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.230300</td>\n",
       "      <td>1.137372</td>\n",
       "      <td>0.831700</td>\n",
       "      <td>0.552500</td>\n",
       "      <td>0.695100</td>\n",
       "      <td>0.694800</td>\n",
       "      <td>13.561400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.325900</td>\n",
       "      <td>1.102398</td>\n",
       "      <td>0.832800</td>\n",
       "      <td>0.553700</td>\n",
       "      <td>0.696900</td>\n",
       "      <td>0.696800</td>\n",
       "      <td>13.589700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.367300</td>\n",
       "      <td>1.094201</td>\n",
       "      <td>0.833400</td>\n",
       "      <td>0.556500</td>\n",
       "      <td>0.698600</td>\n",
       "      <td>0.698500</td>\n",
       "      <td>13.570000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MyProjects\\DawsonAI\\.env\\Lib\\site-packages\\transformers\\generation\\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "D:\\MyProjects\\DawsonAI\\.env\\Lib\\site-packages\\transformers\\generation\\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "D:\\MyProjects\\DawsonAI\\.env\\Lib\\site-packages\\transformers\\generation\\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "D:\\MyProjects\\DawsonAI\\.env\\Lib\\site-packages\\transformers\\generation\\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1832, training_loss=1.462356892735677, metrics={'train_runtime': 869.3841, 'train_samples_per_second': 33.679, 'train_steps_per_second': 2.107, 'total_flos': 186238777688064.0, 'train_loss': 1.462356892735677, 'epoch': 4.0})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7ebb24b0-eb00-47ee-ba3f-78a3121ca99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "mcq_model = AutoModelForSeq2SeqLM.from_pretrained(\"results_old_qasc/checkpoint-1374\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32e6ecf0-26ba-4b77-a031-09c2f9b7bbb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Don't forget to add the \"ask: \" prompt!\u001b[39;00m\n\u001b[0;32m      2\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask: Genetic engineering is manipulation of an organism\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms genes using technology.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(input_text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[0;32m      5\u001b[0m outputs \u001b[38;5;241m=\u001b[39m mcq_model\u001b[38;5;241m.\u001b[39mgenerate(input_ids, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Don't forget to add the \"ask: \" prompt!\n",
    "input_text = \"ask: Genetic engineering is manipulation of an organism's genes using technology.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = mcq_model.generate(input_ids, max_new_tokens=100, do_sample=False)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d5b5ee-6c53-4180-9722-add154833782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
